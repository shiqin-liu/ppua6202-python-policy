{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 4: Working with data and files\n",
    "\n",
    "So far, we’ve figured out how to do many things with Python already:\n",
    "- Data Types: integers, floats, strings\n",
    "- Variables: hold one piece of data of specific type \n",
    "- Containers: hold many pieces of data\n",
    "- Statements and Expressions\n",
    "- Branching\n",
    "- Looping\n",
    "- Functions\n",
    "\n",
    "\n",
    "Next, we will learn to work with hands-on data and introduce useful packages to practice with coding using Python.  \n",
    "\n",
    "In this module, we will introduce [pandas](https://pandas.pydata.org/docs/getting_started/overview.html), a powerful Python package that provides fast, flexible, and expressive data structures that are useful for doing practical, real-world data analysis in Python. We'll learn about how to load, clean and process data, and conduct basic descriptive analysis\n",
    "\n",
    "pandas is based on [numpy](https://numpy.org/doc/stable/user/whatisnumpy.html), one of the most important packages for numerical computing in Python.\n",
    "\n",
    "\n",
    "Relevant reading: McKinney's Python for Data Analysis Chapters 4, 5, 6\n",
    "\n",
    "\n",
    "**Setup virtual environment**  \n",
    "Before you start, let's create a conda environment and install all necessary packadges for this course, following the steps below:\n",
    "1. Download `environment.yml` to your working directories (i.e. course folder)\n",
    "1. Open your anaconda prompt (or a terminal window if using MAC), change directories to your working folder of this course (where your `environment.yml` is located), and run the following commands, one at a time:  \n",
    "    `conda config --add channels conda-forge`   \n",
    "    `conda config --set channel_priority strict`  \n",
    "    `conda env create --file environment.yml --force`  \n",
    "1. It may take a while to complete all the installation, once done, run the following:   \n",
    "    `conda activate ppua6202`    \n",
    "    `python -m ipykernel install --sys-prefix --name ppua6202 --display-name \"Python (ppua6202)\"`   \n",
    "    `jupyter lab`  \n",
    "    \n",
    "You now have a conda environment with all the packages needed for this course, and a Jupyter kernel installed in the environment. Next time you start Jupyter Lab:  \n",
    "1. In your command promt/terminal, run `activate ppua6202` if you're on Windows; or `source activate ppua6202` if you're on Mac.\n",
    "2. Then run `jupyter lab` to open Jupyter Lab in your browser \n",
    "\n",
    "**Download data**  \n",
    "Data for this week can be downloaded from Canvas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import these packages to work with data\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A **module** is a python file (.py) containing Python definitions, statements or functions. \n",
    "\n",
    "**Packages** are a way of structuring Python’s module namespace by using “dotted module names”.\n",
    "\n",
    "**Library** is simply a generic term for a bunch of code that was designed with the aim of being usable by many applications. It coule contain a package or multiple related packages, or a collection of modules or a single module.\n",
    "\n",
    "Check [this issue post on StackOverflow](https://stackoverflow.com/questions/19198166/whats-the-difference-between-a-module-and-a-library-in-python#:~:text=When%20a%20module%2Fpackage%2Fsomething,cannot%20%22run%20a%20library%22.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduce numpy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a python list is a basic data type\n",
    "my_list = [1, 2, 3, 4]\n",
    "my_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a numpy array is like a list, but faster and more compact\n",
    "my_array = np.array([1, 2, 3, 4])\n",
    "my_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can create a numpy array from an existing list too\n",
    "my_array = np.array(my_list)\n",
    "my_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the variable type\n",
    "type(my_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check data type\n",
    "my_array.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "numpy has several mathematical functions built-in. Here are some examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(my_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.std(my_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pandas has two primary data structures we will work with: Series and DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Introduce pandas Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a pandas series is based on a numpy array - it's fast, compact, and has more functionality\n",
    "my_list = [1, 2, 3, 4]\n",
    "my_series = pd.Series(my_list)\n",
    "my_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can create a new Series by passing in a list variable or array\n",
    "# series can contain data types other than just integers\n",
    "series2 = pd.Series(['a', 'b', 'c', 'd'])\n",
    "series2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can change a series's index\n",
    "series2.index = ['w', 'x', 'y']\n",
    "series2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Introduce pandas DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a pandas dataframe is like a table where each column is a series\n",
    "# a dict can contain multiple lists and label them\n",
    "my_dict = {'hh_income'  : [75125, 22075, 31950, 115400],\n",
    "           'home_value' : [525000, 275000, 395000, 985000]}\n",
    "my_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a pandas dataframe can contain multiple columns/series\n",
    "# you can create a dataframe by passing in a list, array, series, or dict\n",
    "df = pd.DataFrame(my_dict)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the row labels in the index are accessed by the .index attribute of the DataFrame object\n",
    "df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the column labels are accessed by the .columns attribute of the DataFrame object\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the data values are accessed by the .values attribute of the DataFrame object\n",
    "df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframe shape as rows, columns\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datatypes of the columns\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Working with CSV files\n",
    "\n",
    "In practice, you'll work with data by loading a dataset file into pandas. CSV is the most common format. But pandas can also ingest tab-separated data, JSON, and proprietary file formats like Excel .xlsx files, Stata, SAS, and SPSS.\n",
    "\n",
    "Notice what pandas's `read_csv` function does:\n",
    "\n",
    "1. recognize the header row and get its variable names\n",
    "1. read all the rows and construct a pandas DataFrame, an assembly of pandas Series\n",
    "1. construct a unique index, beginning with zero\n",
    "1. infer the data type of each variable (ie, column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas can load CSV files as DataFrames - it pulls column labels from the first row of the data file\n",
    "df = pd.read_csv('../data/rain.csv') # path relative to notebook file\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframe shape as rows, columns\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datatypes of the columns\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We can select subsets of the rows by indexing, and select specific columns by their name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a column is a pandas series\n",
    "type(df['rainfall_inches'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# so is a row\n",
    "type(df.loc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view a column\n",
    "df['rainfall_inches']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort the values\n",
    "df.sort_values('rainfall_inches', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view the \"head\" of the dataframe\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# or view its \"tail\"\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first 6 elements\n",
    "df['rainfall_inches'][:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final 6 rows\n",
    "df[6:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summary descriptive stats\n",
    "df['rainfall_inches'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It silently handles the missing value for September and gave the correct statistical results. These are essentially Numpy functions, but in pandas we can now deal with multiple data types and columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['rainfall_inches'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['rainfall_inches'].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now it's your turn\n",
    "# how would you compute the total rainfall inches between march and august?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### More DataFrame functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load a new data file\n",
    "df2 = pd.read_csv('../data/cities.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can view the first few or the last few rows of a DataFrame with the .head() or .tail() methods\n",
    "df2.head(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can add a new (empty) column to a DataFrame\n",
    "df2['country'] = np.nan\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can update the values of an entire column in one fell swoop\n",
    "df2['country'] = 'USA'\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can set the values of a column (aka, Series) in the DataFrame to a list of values\n",
    "df2['country'] = ['USA', 'United States'] * 4\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can use fast vectorized methods on a pandas series (aka, a column in our dataframe)\n",
    "df2['country'].str.replace('United States', 'USA')\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "that didn't do anything to our dataframebecause .str.replace() returns the updated version - it doesn't perform the operation in place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need to capture the updated values when they get returned\n",
    "df2['country'] = df2['country'].str.replace('United States', 'USA')\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can change the column names\n",
    "df2.columns = ['city_name', 'state_name', 'nation']\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# or just rename a single column, passing a dict into the rename() method\n",
    "df2 = df2.rename(columns={'city_name':'city'})\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.drop(columns=['nation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you could combine the value into one column seperated by comma\n",
    "df2['city_state'] = df2['city'] + ', ' + df2['state_name']\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you could also split them\n",
    "# Adding two new columns to the existing dataframe.\n",
    "# splitting is done on the basis of underscore.\n",
    "df2[['city1','state1']] = df2['city_state'].str.split(\", \", expand=True)\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can save your DataFrame as a csv file\n",
    "df2.to_csv('../data/my_new_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now it's your turn\n",
    "# rename all the columns to new names and save to disk as a new file\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering on values\n",
    "\n",
    "You can easily filter a dataframe for one or more conditions based on the values in a column. Below we filter df to select only months with less than 3 inches of rainfall.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df[df['rainfall_inches'] < 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['rainfall_inches'] < 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = df['rainfall_inches'] < 3\n",
    "df[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.isnull(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.notnull(df['rainfall_inches'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also select rows based on the values of more than one column. Just remember to nest the individual conditions within parentheses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[(df['month'] != 'jul') & (pd.notnull(df['rainfall_inches']))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What's that funny ampersand doing there? We'll learn more next week!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now it's your turn\n",
    "# what is the average rainfall in months with at least 2 inches of rain?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Editing strings and changing data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['rainfall_inches']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count non-nan cells\n",
    "df['rainfall_inches'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count all cells, including nans\n",
    "len(df['rainfall_inches'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['rainfall_inches'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill missing values with a default value (or you could drop them instead!)\n",
    "df['rainfall_inches'] = df['rainfall_inches'].fillna(0)\n",
    "df['rainfall_inches']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now convert to int\n",
    "df['rainfall_inches'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remember to re-assign to capture the output!\n",
    "df['rainfall_inches'] = df['rainfall_inches'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df[df['month'].str.contains('j')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can do stats on a filtered subset\n",
    "df[df['month'].str.contains('j')]['rainfall_inches'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
