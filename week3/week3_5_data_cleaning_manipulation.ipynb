{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Module 5: Data cleaning and manipulation\n",
    "\n",
    "In the previous module, we learn the basic of working with data and file with pandas. In this module, we are going to work with a real-world dataset, and learn how to clean, select, filter, and slice data from a dataset, and merge and concatenate datasets.\n",
    "\n",
    "Relevant reading: McKinney's Python for Data Analysis Chapters 7-8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What are the data?  \n",
    "We will be working with [2017 5-year tract-level ACS](https://www.census.gov/data/developers/data-sets/acs-5year.2017.html) from the Census Bureau, Below is the descriptive tables of the dataset. It's a set of socioeconomic variables across all Massachusetts census tracts:\n",
    "\n",
    "\n",
    "\n",
    "##### Table 1: Variable Names and ACS Dataset\n",
    "\n",
    "\n",
    "|variable | ACS dataset | description |\n",
    "|---- | --- | --- |\n",
    "|tot_pop | DP05_0001E | Total population |\n",
    "|age2034 | DP05_0009PE| Percent of population 20–34 years old |\n",
    "| age65up | DP05_0024PE  | Percent of population 65 years and older |\n",
    "|black | DP05_0078PE |Percent of population that is non-Hispanic Black/African American|\n",
    "|hispanic | DP05_0070PE | Percent of population that is Hispanic/Latino |\n",
    "|asian | DP05_0080PE | Percent of population that is non-Hispanic Asian |\n",
    "|white | DP05_0077PE | Percent of population that is non-Hispanic White |\n",
    "|pct_college_degree_higher | DP02_0067PE | Percent of population (25 years and older) with bachelor’s degree or higher |\n",
    "| pct_college_grad_student | DP02_0057PE | Percent of population who currently enroll in college or grad school | \n",
    "| hhincome | DP03_0062E | Median household income (US dollars) |\n",
    "| pct_male | DP05_0002PE | Percent of population that is male |\n",
    "| pct_female | DP05_0003PE | Percent of population that is female |\n",
    "| poverty | DP03_0128PE | Percent of families and people whose income in the past 12 months is below the poverty level |\n",
    "| mean_commute_time | DP03_0025E | Workers 16 years and over: Mean travel time to work (minutes) |\n",
    "| pct_english_only | DP02_0111PE | Percent of population with english as only language spoken at home | \n",
    "| pct_foreign_born | DP02_0092PE | Percent of population that are foreign borned |\n",
    "| median_rent | DP04_0134E | Occupied units paying rent: Median gross rent (US dollars)|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load a data file\n",
    "# note the relative filepath! where is this file located?\n",
    "df = pd.read_csv('../data/acs_data_tracts_MA.csv', dtype={'GEOID':str})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1478, 21)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dataframe shape as rows, columns\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1478"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# or use len to just see the number of rows\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>GEOID</th>\n",
       "      <th>stateID</th>\n",
       "      <th>countyID</th>\n",
       "      <th>population_size</th>\n",
       "      <th>age2034</th>\n",
       "      <th>age65up</th>\n",
       "      <th>black</th>\n",
       "      <th>hispanic</th>\n",
       "      <th>asian</th>\n",
       "      <th>...</th>\n",
       "      <th>pct_college_degree_higher</th>\n",
       "      <th>pct_college_grad_student</th>\n",
       "      <th>hhincome</th>\n",
       "      <th>pct_male</th>\n",
       "      <th>pct_female</th>\n",
       "      <th>poverty</th>\n",
       "      <th>mean_commute_time</th>\n",
       "      <th>pct_english_only</th>\n",
       "      <th>pct_foreign_born</th>\n",
       "      <th>median_rent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>25001010100</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>2952</td>\n",
       "      <td>3.0</td>\n",
       "      <td>28.9</td>\n",
       "      <td>1.7</td>\n",
       "      <td>2952</td>\n",
       "      <td>1.6</td>\n",
       "      <td>...</td>\n",
       "      <td>48.8</td>\n",
       "      <td>47.4</td>\n",
       "      <td>47500.0</td>\n",
       "      <td>53.3</td>\n",
       "      <td>46.7</td>\n",
       "      <td>10.7</td>\n",
       "      <td>13.9</td>\n",
       "      <td>88.5</td>\n",
       "      <td>9.2</td>\n",
       "      <td>1120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>25001010206</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>3171</td>\n",
       "      <td>8.2</td>\n",
       "      <td>38.1</td>\n",
       "      <td>2.2</td>\n",
       "      <td>3171</td>\n",
       "      <td>3.4</td>\n",
       "      <td>...</td>\n",
       "      <td>52.6</td>\n",
       "      <td>27.5</td>\n",
       "      <td>59042.0</td>\n",
       "      <td>44.3</td>\n",
       "      <td>55.7</td>\n",
       "      <td>11.3</td>\n",
       "      <td>22.6</td>\n",
       "      <td>95.3</td>\n",
       "      <td>7.8</td>\n",
       "      <td>1027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>25001010208</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>1580</td>\n",
       "      <td>2.1</td>\n",
       "      <td>37.3</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1580</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>45.9</td>\n",
       "      <td>9.5</td>\n",
       "      <td>62844.0</td>\n",
       "      <td>50.4</td>\n",
       "      <td>49.6</td>\n",
       "      <td>11.2</td>\n",
       "      <td>16.8</td>\n",
       "      <td>93.6</td>\n",
       "      <td>9.6</td>\n",
       "      <td>1019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>25001010304</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>2332</td>\n",
       "      <td>7.7</td>\n",
       "      <td>43.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>2332</td>\n",
       "      <td>4.8</td>\n",
       "      <td>...</td>\n",
       "      <td>51.2</td>\n",
       "      <td>30.2</td>\n",
       "      <td>71250.0</td>\n",
       "      <td>44.2</td>\n",
       "      <td>55.8</td>\n",
       "      <td>4.8</td>\n",
       "      <td>23.5</td>\n",
       "      <td>93.7</td>\n",
       "      <td>7.0</td>\n",
       "      <td>980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>25001010306</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>2576</td>\n",
       "      <td>4.4</td>\n",
       "      <td>33.2</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2576</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>45.1</td>\n",
       "      <td>10.2</td>\n",
       "      <td>55694.0</td>\n",
       "      <td>47.7</td>\n",
       "      <td>52.3</td>\n",
       "      <td>8.2</td>\n",
       "      <td>17.8</td>\n",
       "      <td>96.9</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1176</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0        GEOID  stateID  countyID  population_size  age2034  \\\n",
       "0           0  25001010100       25         1             2952      3.0   \n",
       "1           1  25001010206       25         1             3171      8.2   \n",
       "2           2  25001010208       25         1             1580      2.1   \n",
       "3           3  25001010304       25         1             2332      7.7   \n",
       "4           4  25001010306       25         1             2576      4.4   \n",
       "\n",
       "   age65up  black  hispanic  asian  ...  pct_college_degree_higher  \\\n",
       "0     28.9    1.7      2952    1.6  ...                       48.8   \n",
       "1     38.1    2.2      3171    3.4  ...                       52.6   \n",
       "2     37.3    1.3      1580    0.0  ...                       45.9   \n",
       "3     43.4    0.9      2332    4.8  ...                       51.2   \n",
       "4     33.2    3.5      2576    0.5  ...                       45.1   \n",
       "\n",
       "   pct_college_grad_student  hhincome  pct_male  pct_female  poverty  \\\n",
       "0                      47.4   47500.0      53.3        46.7     10.7   \n",
       "1                      27.5   59042.0      44.3        55.7     11.3   \n",
       "2                       9.5   62844.0      50.4        49.6     11.2   \n",
       "3                      30.2   71250.0      44.2        55.8      4.8   \n",
       "4                      10.2   55694.0      47.7        52.3      8.2   \n",
       "\n",
       "   mean_commute_time  pct_english_only  pct_foreign_born  median_rent  \n",
       "0               13.9              88.5               9.2         1120  \n",
       "1               22.6              95.3               7.8         1027  \n",
       "2               16.8              93.6               9.6         1019  \n",
       "3               23.5              93.7               7.0          980  \n",
       "4               17.8              96.9               5.0         1176  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view the dataframe's \"head\"\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Clean and process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data types of the columns\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# access a single column like df['col_name']\n",
    "df['median_rent'].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas uses numpy's nan to represent null (missing) values\n",
    "print(np.nan)\n",
    "print(type(np.nan))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert rent from string -> float\n",
    "df['median_rent'].astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Didn't work! We need to clean up the stray alphabetical characters to get a numerical value. You can do string operations on pandas Series to clean up their values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do a string replace and assign back to that column, then change type to float\n",
    "df['median_rent'] = df['median_rent'].str.replace(' (USD)', '', regex=False)\n",
    "df['median_rent'] = df['median_rent'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert rent from float -> int\n",
    "df['median_rent'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You cannot store null values as type `int`, only as type `float`. You have three basic options:\n",
    "\n",
    "  1. Keep the column as float to retain the nulls - they are often important!\n",
    "  2. Drop all the rows that contain nulls if we need non-null data for our analysis\n",
    "  3. Fill in all the nulls with another value if we know a reliable default value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop rows that contain nulls\n",
    "# this doesn't save the result, because we didn't reassign! (in reality, want to keep the nulls here)\n",
    "df.dropna(subset=['median_rent']).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill in rows that contain nulls\n",
    "# this doesn't save the result, because we didn't reassign! (in reality, want to keep the nulls here)\n",
    "df['median_rent'].fillna(value=0).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['stateID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dict that maps state fips code -> state name\n",
    "fips = {25 : 'MA'}\n",
    "\n",
    "# replace fips code with state name with the replace() method\n",
    "df['stateID'] = df['stateID'].replace(fips)\n",
    "df['stateID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can rename columns with the rename() method\n",
    "# remember to reassign to save the result\n",
    "df = df.rename(columns={'stateID' : 'state_name'})\n",
    "\n",
    "df = df.rename(columns={'population_size' : 'total_pop'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can drop columns you don't need with the drop() method\n",
    "# remember to reassign to save the result\n",
    "df = df.drop(columns=['Unnamed: 0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect the cleaned-up dataframe\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save it to disk as a \"clean\" copy\n",
    "# note the relative filepath\n",
    "df.to_csv('../data/acs_data_tracts_MA-clean.csv', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Selecting and slicing data from a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHEAT SHEET OF COMMON TASKS\n",
    "# Operation                       Syntax           Result\n",
    "#------------------------------------------------------------\n",
    "# Select column by name           df[col]          Series\n",
    "# Select columns by name          df[col_list]     DataFrame\n",
    "# Select row by label             df.loc[label]    Series\n",
    "# Select row by integer location  df.iloc[loc]     Series\n",
    "# Slice rows by label             df.loc[a:c]      DataFrame\n",
    "# Select rows by boolean vector   df[mask]         DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3a. Select DataFrame's column(s) by name\n",
    "\n",
    "We saw some of this a minute ago. Let's look in a bit more detail and break down what's happening."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select a single column by column name\n",
    "# this is a pandas series\n",
    "df['total_pop']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select multiple columns by a list of column names\n",
    "# this is a pandas dataframe that is a subset of the original\n",
    "df[['total_pop', 'hhincome']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new column by assigning df['new_col'] to some set of values\n",
    "# you can do math operations on any numeric columns\n",
    "df['monthly_income'] = df['hhincome'] / 12\n",
    "df['rent_burden'] = df['median_rent'] / df['monthly_income']\n",
    "\n",
    "# inspect the results\n",
    "df[['hhincome', 'monthly_income', 'median_rent', 'rent_burden']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3b. Select row(s) by label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use .loc to select by row label\n",
    "# returns the row as a series whose index is the dataframe column names\n",
    "df.loc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use .loc to select single value by row label, column name\n",
    "df.loc[0, 'poverty']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# slice of rows from label 5 to label 7, inclusive\n",
    "# this returns a pandas dataframe\n",
    "df.loc[5:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# slice of rows from label 1 to label 3, inclusive\n",
    "# slice of columns from hispanic to white, inclusive\n",
    "df.loc[1:3, 'hispanic':'white']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subset of rows from with labels in list\n",
    "# subset of columns with names in list\n",
    "df.loc[[1, 3], ['hispanic', 'white']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can use a column of unique identifiers as the index\n",
    "# fips codes uniquely identify each row (but verify!)\n",
    "df = df.set_index('GEOID')\n",
    "df.index.is_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# .loc works by label, not by position in the dataframe\n",
    "df.loc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the index now contains fips codes, so you have to use .loc accordingly to select by row label\n",
    "df.loc['25001010100']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3c. Select by (integer) position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the row in the zero-th position in the dataframe\n",
    "df.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can slice as well\n",
    "# note, while .loc[] is inclusive, .iloc[] is not\n",
    "# get the rows from position 0 up to but not including position 3 (ie, rows 0, 1, and 2)\n",
    "df.iloc[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the value from the row in position 3 and the column in position 2 (zero-indexed)\n",
    "df.iloc[3, 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3d. Select/filter by value\n",
    "\n",
    "You can subset or filter a dataframe based on the values in its rows/columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter the dataframe by rows with 30%+ rent burden\n",
    "df[df['rent_burden'] > 0.3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what exactly did that do? let's break it out.\n",
    "df['rent_burden'] > 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# essentially a true/false mask that filters by value\n",
    "mask = df['rent_burden'] > 0.3\n",
    "df[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can chain multiple conditions together\n",
    "# pandas logical operators are: | for or, & for and, ~ for not\n",
    "# these must be grouped by using parentheses due to order of operations\n",
    "# question: which tracts are both rent-burdened and majority-Black?\n",
    "mask = (df['rent_burden'] > 0.3) & (df['black'] > 50)\n",
    "df[mask].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# which tracts are both rent-burdened and either majority-Black or majority-Hispanic?\n",
    "mask1 = df['rent_burden'] > 0.3\n",
    "mask2 = df['black'] > 50\n",
    "mask3 = df['hispanic'] > 50\n",
    "mask = mask1 & (mask2 | mask3)\n",
    "df[mask].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see the mask\n",
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ~ means not... it essentially flips trues to falses and vice-versa\n",
    "~mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now it's your turn\n",
    "# create a new subset dataframe containing all the rows with median household income above $60,000 and percent-White above 60%\n",
    "# how many rows did you get?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Merge and concatenate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4a. Merging DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a subset dataframe with only race/ethnicity variables\n",
    "race_cols = ['asian', 'black', 'hispanic', 'white']\n",
    "df_race = df[race_cols]\n",
    "df_race.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a subset dataframe with only economic variables\n",
    "econ_cols = ['median_rent', 'hhincome']\n",
    "df_econ = df[econ_cols].sort_values('hhincome')\n",
    "df_econ.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge them together, aligning rows based on their labels in the index\n",
    "df_merged = pd.merge(left=df_econ, right=df_race, how='inner', left_index=True, right_index=True)\n",
    "df_merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now it's your turn\n",
    "# change the \"how\" argument: what happens if you try an \"outer\" join? or a \"left\" join? or a \"right\" join?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset df_econ's index\n",
    "df_econ = df_econ.reset_index()\n",
    "df_econ.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge them together, aligning rows based on their labels in the index\n",
    "# doesn't work! their indexes do not share any labels to match/align the rows\n",
    "df_merged = pd.merge(left=df_econ, right=df_race, how='inner', left_index=True, right_index=True)\n",
    "df_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instead merge where df_race index matches df_econ GEOID10 column\n",
    "df_merged = pd.merge(left=df_econ, right=df_race, how='inner', left_on='GEOID', right_index=True)\n",
    "df_merged.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4b. Concatenating DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select data within suffolk county, the county id is 25\n",
    "df_suffolk = df[df['countyID']==25]\n",
    "\n",
    "# select data within middlesex county, the county id is 17\n",
    "df_middlesex = df[df['countyID']==17]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merging joins data together aligned by the index, but concatenating just smushes it together along some axis\n",
    "df_all = pd.concat([df_middlesex, df_suffolk], sort=False)\n",
    "df_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "1. The basics of numpy arrays and pandas dataframes \n",
    "2. Loading and working with files in pandas\n",
    "    - Selecting, filtering and slicing data\n",
    "    - Saving a dataframe as a file\n",
    "    - Other dataframes functionalities\n",
    "3. Data cleaning and processing\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 3\n",
    "\n",
    "See instrutions on Canvas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
